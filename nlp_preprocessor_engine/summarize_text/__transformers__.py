from transformers import pipeline


def summarize_text(text: str, max_length: int = 50, min_length: int = 10, do_sample: bool = False) -> str:
    """
    Summarizes the input text using the pre-trained BERT model from the Hugging Face Transformers library.

    Args:
    - text (str): The input text to be summarized.
    - max_length (int): The maximum length of the summary, in tokens. Default is 50.
    - min_length (int): The minimum length of the summary, in tokens. Default is 10.
    - do_sample (bool): Whether to use sampling or greedy decoding to generate the summary. Default is False.

    Returns:
    - str: A summary of the input text, generated by the pre-trained BERT model.
    """
    # Load the pre-trained BERT model for summarization
    summarizer = pipeline("summarization", model="bert-base-uncased", tokenizer="bert-base-uncased")

    # Generate a summary of the input text
    output = summarizer(text, max_length=max_length, min_length=min_length, do_sample=do_sample)

    # Extract the summary text from the output
    summary = output[0]['summary_text']

    return summary
